# OffLine_DataWareHouse
项目背景：随着网络电商的兴起并不断发展，企业对于用户的行为和购买倾向需求大大提高。本项目基于此背景下收集数据，并对数据经过清洗、过滤、分析，获取有用及所需的数据用于展示和分析，便于企业对自身产品有更进一步的分析与决策。  技术架构：`Flume` `Kafka` `Spark` `Sqoop` `MySQL` `Hive` `HDFS`  

项目实现：

- 数据采集：项目数据主要涉及用户行为数据和业务交互数据，基于SpringBoot的开源程序读取两类数据，并存储在磁盘文件和数据库中

- 数据分析：使用DataX工具根据业务数据的特性选择相应的同步策略将业务数据从MySQL导入到HDFS中，使用Flume+Kafka组件将用户行为数据存储到HDFS中（中间可以通过Kafka的拦截器对数据进行简单的ETL，此外考虑到数据背压和零点漂移问题使用Kafka+Flume架构）。

- 数据建模：明确数仓分层和建模类型，根据业务需求确立事实表与维度表,（考虑到Hive使用MapReduce计算引擎的速率问题，整合Hive on Spark提高计算效率）,在Hive中建立业务表格，如：订单表、支付表等，读取订单、支付业务数据，提取相应的字段进行需求表格构建，并导入数据。
